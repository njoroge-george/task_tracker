# AI Features Testing Guide ğŸ¤–

## âœ… Setup Complete!

All AI features are now installed and configured:
- âœ… OpenAI package installed (`openai` v4.x)
- âœ… API key configured in `.env`
- âœ… Model updated to `gpt-4o-mini` (latest, faster, cheaper)
- âœ… Mock fallback system ready (works without API key)

---

## ğŸ§ª How to Test AI Features

### 1. **Task Suggestions** (Auto-generate task details)

**Where:** `/dashboard/tasks` â†’ Click "+ New Task"

**How to test:**
1. Type a task title like: "Build user authentication system"
2. Wait 1 second
3. See AI suggestions appear in a blue banner
4. Click **"Apply"** to auto-fill the form

**What AI generates:**
- Description (detailed explanation)
- Priority (based on keywords: urgent, critical, etc.)
- Estimated time (in minutes)
- Due date (if mentioned in title)
- Tags (relevant keywords)

**Test cases:**
```
âœ“ "Fix critical login bug ASAP" â†’ HIGH priority, urgent tag
âœ“ "Design homepage mockup" â†’ MEDIUM priority, design tag
âœ“ "Update documentation" â†’ LOW priority, docs tag
âœ“ "Team meeting tomorrow at 2pm" â†’ Due date auto-filled
```

---

### 2. **Natural Language Parsing** (Parse complex task descriptions)

**API:** `POST /api/ai/parse-task`

**Test via CreateTaskDialog:**
- Type complex sentences and see how AI extracts:
  - Title
  - Description
  - Priority
  - Due date
  - Assignee

**Example:**
```
Input: "Need to fix the critical payment bug by Friday, assign to John, high priority"

Output:
- Title: Fix critical payment bug
- Priority: HIGH
- Due date: Next Friday
- Assignee: John
```

---

### 3. **Title Enhancement** (Improve task titles)

**Where:** CreateTaskDialog â†’ Click lightbulb icon ğŸ’¡

**How to test:**
1. Type a vague title: "fix stuff"
2. Click the enhance button
3. See improved title like: "Debug and resolve system issues"

**Test cases:**
```
âœ“ "fix stuff" â†’ "Debug and resolve system issues"
âœ“ "meeting" â†’ "Schedule team coordination meeting"
âœ“ "bug" â†’ "Investigate and fix reported bug"
```

---

### 4. **Duplicate Detection** (Find similar tasks)

**Where:** Automatic when creating tasks

**How to test:**
1. Create a task: "Implement user authentication"
2. Try to create another: "Build authentication system"
3. See warning: âš ï¸ "Similar task exists: Implement user authentication"

**What AI does:**
- Compares semantic meaning (not just keywords)
- Prevents duplicate work
- Shows existing similar tasks

---

### 5. **Daily Summary** (AI-generated productivity report)

**API:** `GET /api/ai/daily-summary?userId=<id>`

**Test in browser console:**
```javascript
fetch('/api/ai/daily-summary?userId=YOUR_USER_ID')
  .then(r => r.json())
  .then(console.log)
```

**What AI generates:**
- Summary of tasks completed today
- Progress analysis
- Suggestions for tomorrow
- Productivity insights

---

### 6. **Smart Tagging** (Auto-suggest relevant tags)

**API:** `POST /api/ai/suggest-tags`

**Integrated in CreateTaskDialog:**
- Type task title/description
- AI suggests relevant tags
- Click to apply

**Examples:**
```
"Fix login API bug" â†’ ["backend", "api", "bug", "authentication"]
"Design landing page" â†’ ["frontend", "design", "ui", "marketing"]
"Write unit tests" â†’ ["testing", "development", "quality"]
```

---

## ğŸ­ Mock Mode (No API Key Required)

If `OPENAI_API_KEY` is not set, AI features fall back to **smart keyword detection**:

- **HIGH priority**: urgent, critical, asap, emergency, blocker
- **MEDIUM priority**: important, should, need
- **Design tags**: design, ui, ux, mockup, wireframe
- **Dev tags**: code, implement, build, develop, create
- **Bug tags**: fix, bug, issue, error, problem
- **Time estimates**: Simple: 30 min, Medium: 120 min, Complex: 240 min

**Mock mode is perfect for:**
- Development without API costs
- Demos and testing
- Offline work

---

## ğŸ“Š Expected Behavior

### âœ… Success Indicators:
- Blue suggestion banner appears within 1-2 seconds
- "Apply" button fills form fields correctly
- Similar tasks warning shows relevant matches
- Enhanced titles are more specific and actionable

### âš ï¸ If AI Fails:
- Mock fallback activates automatically
- You'll see keyword-based suggestions
- No errors, just simpler suggestions

---

## ğŸ”‘ API Key Notes

Your current key: `sk-proj-X2Tr...1uAA` (configured âœ…)

**Model used:** `gpt-4o-mini`
- Faster than GPT-4 Turbo
- 60% cheaper
- Perfect for task suggestions
- Better structured output

**Cost estimate:**
- ~$0.0001 per task suggestion
- 10,000 tasks = ~$1
- Very affordable for production use

---

## ğŸ› Troubleshooting

### AI suggestions not appearing?
1. Check browser console for errors
2. Verify API key in `.env`: `OPENAI_API_KEY=sk-...`
3. Restart dev server: `npm run dev`
4. Test mock mode by removing API key temporarily

### "Model not found" errors?
âœ… **FIXED!** Updated from `gpt-4-turbo-preview` â†’ `gpt-4o-mini`

### Slow responses?
- Normal: AI takes 1-3 seconds
- Use mock mode for instant responses
- Consider caching common suggestions

---

## ğŸš€ Next Steps

1. **Test each feature** using the guide above
2. **Try edge cases** (empty titles, very long descriptions, special characters)
3. **Check mock fallback** (temporarily remove API key)
4. **Monitor costs** in OpenAI dashboard
5. **Customize prompts** in `src/lib/ai.ts` for your use case

---

## ğŸ“ Files Modified

- âœ… `src/lib/ai.ts` - Core AI service with 6 functions
- âœ… `src/app/api/ai/*/route.ts` - 5 API endpoints
- âœ… `src/components/tasks/CreateTaskDialog.tsx` - UI integration
- âœ… `.env` - API key configuration
- âœ… `package.json` - OpenAI dependency added

---

## ğŸ’¡ Pro Tips

1. **Use descriptive titles** - AI works better with context
2. **Include keywords** - Priority words, time estimates, dates
3. **Test mock mode first** - Verify UI before using API
4. **Customize prompts** - Edit `src/lib/ai.ts` to match your workflow
5. **Monitor usage** - Check OpenAI dashboard regularly

---

**All AI features are ready! Start testing at:** `/dashboard/tasks` ğŸ‰
